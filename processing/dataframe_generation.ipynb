{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read timelines and match ids and tournament ids\n",
    "timelines_df = pd.read_csv('../data/match_timelines.csv')\n",
    "team_names_df = pd.read_csv('../data/match_ids.csv')\n",
    "tournaments_df = pd.read_csv('../data/tournament_ids.csv')\n",
    "\n",
    "# select correct tournaments\n",
    "tournaments_df = tournaments_df[tournaments_df['tournament_id'].isin([57, 58, 59, 60, 61, 62, 102, 103, 104, 105, 106, 107, 152, 153, 154, 155, 156, 157])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column of age group and gender\n",
    "tournaments_df['age'] = ['F12', 'M12', 'F13', 'F14', 'M13', 'M14',\n",
    "                         'M13', 'F13', 'F12', 'M12', 'F14', 'M14',\n",
    "                         'M13', 'F12', 'F13', 'F14', 'M14', 'M12']\n",
    "\n",
    "# create year column from name\n",
    "tournaments_df['year'] = tournaments_df['name'].str.extract(r'(\\d{4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list international teams\n",
    "int_teams = ['Nords', 'jylland', 'Shamrock', 'Hamma', 'ndby', 'Vitesse', 'Bromma', 'Liding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boolean variables for international teams\n",
    "team_names_df['home_team_int'] = team_names_df['home_team'].apply(lambda x: 1 if any(sub in x for sub in int_teams) else 0)\n",
    "team_names_df['away_team_int'] = team_names_df['away_team'].apply(lambda x: 1 if any(sub in x for sub in int_teams) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add home and away team names to main dataframe\n",
    "timelines_df = timelines_df.merge(team_names_df, on=['tournament_id', 'match_id'], how='left')\n",
    "\n",
    "# add year and age group to main dataframe\n",
    "timelines_df = timelines_df.merge(tournaments_df.drop('name', axis=1), on=['tournament_id'], how='left')\n",
    "\n",
    "# convert times to datetime objects\n",
    "# Convert to datetime\n",
    "timelines_df['start_time'] = pd.to_datetime(timelines_df['start_time'], format='mixed')\n",
    "timelines_df['end_time'] = pd.to_datetime(timelines_df['end_time'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(x1, y1, x2, y2):\n",
    "    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "# Apply distance calculation for \"Pass\" and \"Dribble\" events\n",
    "timelines_df['distance'] = np.where(\n",
    "    timelines_df['event_type'].isin(['Pass', 'Dribble']), \n",
    "    euclidean_distance(timelines_df['start_position_x'], timelines_df['start_position_y'], timelines_df['end_position_x'], timelines_df['end_position_y']),\n",
    "    np.nan  # Assign NaN for other events\n",
    ")\n",
    "\n",
    "# calculate duration of event for possible events\n",
    "timelines_df['duration'] = timelines_df['end_time'] - timelines_df['start_time']\n",
    "timelines_df['duration'] = timelines_df['duration'].dt.total_seconds() #convert to seconds\n",
    "\n",
    "# calculate speed for possible events\n",
    "timelines_df['speed'] = np.where(\n",
    "    timelines_df['event_type'].isin(['Pass', 'Dribble']), \n",
    "    timelines_df['distance'] / timelines_df['duration'],\n",
    "    timelines_df['speed']\n",
    ")\n",
    "\n",
    "# create column of international level (0=f-f, 1=i-f, 2=i-i)\n",
    "timelines_df['int_level'] = timelines_df['home_team_int'] | timelines_df['away_team_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform second period into an extension of the first period\n",
    "\n",
    "# remove matches where there is no first period\n",
    "valid_matches = timelines_df[timelines_df['period'] == 1]['match_id'].unique()\n",
    "timelines_df = timelines_df[timelines_df['match_id'].isin(valid_matches)]\n",
    "\n",
    "# timestamp of last event of first period\n",
    "first_period_durations = timelines_df[timelines_df['period'] == 1].groupby('match_id')['seconds_from_period_start'].max()\n",
    "\n",
    "# transform second period timestamps\n",
    "def transform_time(row):\n",
    "    if row['period'] == 2:\n",
    "        return row['seconds_from_period_start'] + first_period_durations[row['match_id']]\n",
    "    return row['seconds_from_period_start']\n",
    "\n",
    "timelines_df['seconds_from_period_start'] = timelines_df.apply(transform_time, axis=1)\n",
    "\n",
    "# drop the 'period' column as it is no longer needed\n",
    "# timelines_df = timelines_df.drop(columns=['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = 900\n",
    "# timelines_df[timelines_df['match_id'] == 1346]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# match ids and group into groups of 50\n",
    "match_ids = timelines_df['match_id'].unique()\n",
    "match_groups = [match_ids[i:i + 50] for i in range(0, len(match_ids), 50)]\n",
    "\n",
    "# plot \n",
    "\n",
    "# count occurrences of each event_type per match a few matches at a time\n",
    "# for matches in match_groups:\n",
    "#     event_counts = timelines_df[timelines_df['match_id'].isin(matches)].pivot_table(index='match_id', columns='event_type', aggfunc='size', fill_value=0)\n",
    "#     event_counts.plot(kind='bar', stacked=True, figsize=(15, 6), colormap='viridis')\n",
    "\n",
    "#     plt.xlabel(\"Match ID\")\n",
    "#     plt.ylabel(\"Event Count\")\n",
    "#     plt.title(\"Event Type Distribution per Match\")\n",
    "#     plt.legend(title=\"Event Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove matches that are most likely faulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by matches\n",
    "df_matches = timelines_df.groupby('match_id')\n",
    "\n",
    "# get matches with time gaps between events of over 50 seconds\n",
    "threshold = 50\n",
    "\n",
    "# Compute time gaps\n",
    "timelines_df['time_gap'] = df_matches['seconds_from_period_start'].diff()\n",
    "\n",
    "# Identify matches with gaps above threshold\n",
    "timelines_df['gap_exceeds_threshold'] = timelines_df['time_gap'] > threshold\n",
    "timelines_df['gap_exceeds_threshold_300'] = timelines_df['time_gap'] > 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get matches where two consecutive events are kick-offs\n",
    "timelines_df['consecutive_kickoffs'] = (timelines_df['event_type'] == 'KickOff') & (timelines_df['event_type'].shift(1) == 'KickOff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get matches with under 300 events\n",
    "event_counts = timelines_df.groupby('match_id').size().reset_index(name='event_count')\n",
    "too_few_events_ids = event_counts['match_id'][event_counts['event_count'] < 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove matches with time gaps of over five minutes and matches with less than 300 events\n",
    "remove_match_indices = timelines_df[(timelines_df['gap_exceeds_threshold_300'] == True)]['match_id'].unique()\n",
    "remove_match_indices = list(set(remove_match_indices) | set(too_few_events_ids))\n",
    "timelines_df = timelines_df[~timelines_df['match_id'].isin(remove_match_indices)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale F12 dimensions to the same dimensions as other age groups, since distances are calculated already,\n",
    "# these won't affect the speed calculations\n",
    "\n",
    "length_ratio = 100/63\n",
    "width_ratio = 63/40\n",
    "\n",
    "age_group_mask = timelines_df['age'] == 'F12'\n",
    "timelines_df.loc[age_group_mask, ['start_position_x', 'end_position_x']] = timelines_df.loc[age_group_mask, ['start_position_x', 'end_position_x']]*length_ratio\n",
    "timelines_df.loc[age_group_mask, ['start_position_y', 'end_position_y']] = timelines_df.loc[age_group_mask, ['start_position_y', 'end_position_y']]*width_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some matches are not normalized (meaning that home team always attacks to the right),\n",
    "# check which matches these are and normalize them\n",
    "\n",
    "df_passes = timelines_df[timelines_df['event_type'] == 'Pass']\n",
    "\n",
    "pos_vars = ['start_position_x', 'end_position_x', 'start_position_y', 'end_position_y']\n",
    "\n",
    "for match_id in df_passes['match_id'].unique():\n",
    "    match_id_mask_1 = (timelines_df['match_id'] == match_id) & (timelines_df['period'] == 1)\n",
    "    match_id_mask_2 = (timelines_df['match_id'] == match_id) & (timelines_df['period'] == 2)\n",
    "    match_home_mask_1 = (df_passes.match_id == match_id) & (df_passes.team == 'Home') & (df_passes.period == 1)\n",
    "    pass_dir_avg_x_1 = (df_passes.loc[match_home_mask_1, 'end_position_x'] - df_passes.loc[match_home_mask_1, 'start_position_x']).mean()\n",
    "    match_home_mask_2 = (df_passes.match_id == match_id) & (df_passes.team == 'Home') & (df_passes.period == 2)\n",
    "    pass_dir_avg_x_2 = (df_passes.loc[match_home_mask_2, 'end_position_x'] - df_passes.loc[match_home_mask_2, 'start_position_x']).mean()\n",
    "\n",
    "\n",
    "    match_away_mask_1 = (df_passes.match_id == match_id) & (df_passes.team == 'Away') & (df_passes.period == 1)\n",
    "    a_pass_dir_avg_x_1 = (df_passes.loc[match_away_mask_1, 'end_position_x'] - df_passes.loc[match_away_mask_1, 'start_position_x']).mean()\n",
    "    match_away_mask_2 = (df_passes.match_id == match_id) & (df_passes.team == 'Away') & (df_passes.period == 2)\n",
    "    a_pass_dir_avg_x_2 = (df_passes.loc[match_away_mask_2, 'end_position_x'] - df_passes.loc[match_away_mask_2, 'start_position_x']).mean()\n",
    "        \n",
    "    if pass_dir_avg_x_1 < 0 and a_pass_dir_avg_x_1 > 0:\n",
    "        timelines_df.loc[match_id_mask_1, pos_vars] = timelines_df.loc[match_id_mask_1, pos_vars]*(-1)\n",
    "    if pass_dir_avg_x_2 < 0 and a_pass_dir_avg_x_2 > 0:\n",
    "        timelines_df.loc[match_id_mask_2, pos_vars] = timelines_df.loc[match_id_mask_2, pos_vars]*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can assume that no shots were taken from over 60 meters out, and these are mislabeled so we can correct them\n",
    "timelines_df.loc[(timelines_df['event_type'] == 'Shot') & (timelines_df['team'] == 'Home') & (timelines_df['start_position_x'] < -10), 'team'] = 'Away'\n",
    "timelines_df.loc[(timelines_df['event_type'] == 'Shot') & (timelines_df['team'] == 'Away') & (timelines_df['start_position_x'] > 10), 'team'] = 'Home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix known missed labels of Goals, GoalKicks are also misslabeled but these can be ignored\n",
    "mask1 = (timelines_df['match_id'] == 1298) & (timelines_df['seconds_from_period_start'] == 2072) & (timelines_df['event_type'] == 'Shot')\n",
    "timelines_df.loc[mask1, 'team'] = 'Home'\n",
    "mask2 = (timelines_df['match_id'] == 2290) & (timelines_df['seconds_from_period_start'] == 2053) & (timelines_df['event_type'] == 'Shot')\n",
    "timelines_df.loc[mask2, 'team'] = 'Home'\n",
    "mask3 = (timelines_df['match_id'] == 1258) & (timelines_df['seconds_from_period_start'] == 1518) & (timelines_df['event_type'] == 'Shot')\n",
    "timelines_df.loc[mask3, 'team'] = 'Away'\n",
    "mask4 = (timelines_df['match_id'] == 1307) & (timelines_df['seconds_from_period_start'] == 1117) & (timelines_df['event_type'] == 'Shot')\n",
    "timelines_df.loc[mask4, 'team'] = 'Away'\n",
    "mask5 = (timelines_df['match_id'] == 1304) & (timelines_df['seconds_from_period_start'] == 511) & (timelines_df['event_type'] == 'Shot')\n",
    "timelines_df.loc[mask5, 'team'] = 'Home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unneeded columns\n",
    "timelines_df = timelines_df.drop(['gap_exceeds_threshold', 'gap_exceeds_threshold_300', 'consecutive_kickoffs'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "timelines_df.to_csv('../data/processed_timelines.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
